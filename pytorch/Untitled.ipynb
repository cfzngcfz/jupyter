{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afea00e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b3af41",
   "metadata": {},
   "source": [
    "# list, numpy, tensor相互转化\n",
    "[![](https://mermaid.ink/img/pako:eNp1ks1qwzAMx18l6ORAlwfIYdCP607raRiCSJwlENvBcRil7bG77AV22ROMHQqDwp5nKXuMKXFImbfpJEs_SX8hbyHVmYAY8ko_pAUaG6xXXAVkc2aFarQJgyuy6x0HTFwkUq2sNyzsDsfPj9fu8dC9PXPYBQs2JEJXv5jqrDZpEWEzljM05mctVw7JjZaJa_4vs770OJ-O56fT1_vLlLR_JUnZ3JdERGR1VTaWhT2wZL0_Kl9O2KAlIhhJUeKQflGf-7XhyPqivbBHO6FcwQykMBLLjA6z7WfRhEJIwSEmNxM5tpXlwNWeUGytvt2oFGJrWjGDts7QilWJ9wYlxDlWDUVrVHdaX94iK0nDjTv-8Af23xzAxMU?type=png)](https://mermaid-js.github.io/mermaid-live-editor/edit#pako:eNp1ks1qwzAMx18l6ORAlwfIYdCP607raRiCSJwlENvBcRil7bG77AV22ROMHQqDwp5nKXuMKXFImbfpJEs_SX8hbyHVmYAY8ko_pAUaG6xXXAVkc2aFarQJgyuy6x0HTFwkUq2sNyzsDsfPj9fu8dC9PXPYBQs2JEJXv5jqrDZpEWEzljM05mctVw7JjZaJa_4vs770OJ-O56fT1_vLlLR_JUnZ3JdERGR1VTaWhT2wZL0_Kl9O2KAlIhhJUeKQflGf-7XhyPqivbBHO6FcwQykMBLLjA6z7WfRhEJIwSEmNxM5tpXlwNWeUGytvt2oFGJrWjGDts7QilWJ9wYlxDlWDUVrVHdaX94iK0nDjTv-8Af23xzAxMU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb0f563",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "                             tensor\n",
    "                         ↗          ↘↖\n",
    "torch.as_tensor(list1) ↗              ↘↖torch.as_tensor(arr1)\n",
    "torch.Tensor(list1)  ↗                  ↘↖torch.from_numpy(arr1)\n",
    "torch.tensor(list1)↗       tensor1.numpy()↘↖torch.Tensor(arr1) \n",
    "                 ↗                          ↘↖torch.tensor(arr1)\n",
    "               ↗       array1.tolist()        ↘↖\n",
    "            list      <-----------------        numpy\n",
    "                      ----------------->\n",
    "                      numpy.array(list1)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4cea915",
   "metadata": {},
   "source": [
    "## numpy <-> tensor\n",
    "> Tensors on the CPU and NumPy arrays can share their underlying memory location, and **changing one will change the other**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1672a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before modify: tensor([1, 1, 1])\n",
      "Before modify: tensor([1, 1, 1])\n",
      "Before modify: tensor([1, 1, 1])\n",
      "Before modify: tensor([1., 1., 1.])\n",
      "Before modify: [1 1 1]\n",
      "After modify: tensor([2, 2, 2])\n",
      "After modify: tensor([2, 2, 2])\n",
      "After modify: tensor([1, 1, 1])\n",
      "After modify: tensor([1., 1., 1.])\n",
      "After modify: [2 2 2]\n"
     ]
    }
   ],
   "source": [
    "arr1 = numpy.array([1,1,1])\n",
    "\n",
    "arr2tensor_1 = torch.from_numpy(arr1)    # 共享内存\n",
    "arr2tensor_2 = torch.as_tensor(arr1)     # 共享内存\n",
    "arr2tensor_3 = torch.tensor(arr1)        # 深拷贝\n",
    "arr2tensor_4 = torch.Tensor(arr1)        # 深拷贝\n",
    "tensor2arr_1 = arr2tensor_1.numpy()      # 共享内存\n",
    "\n",
    "print('Before modify:', arr2tensor_1)\n",
    "print('Before modify:', arr2tensor_2)\n",
    "print('Before modify:', arr2tensor_3)\n",
    "print('Before modify:', arr2tensor_4)\n",
    "print('Before modify:', tensor2arr_1)\n",
    "\n",
    "arr1 += 1\n",
    "print('After modify:', arr2tensor_1)\n",
    "print('After modify:', arr2tensor_2)\n",
    "print('After modify:', arr2tensor_3)\n",
    "print('After modify:', arr2tensor_4)\n",
    "print('After modify:', tensor2arr_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3f16a4",
   "metadata": {},
   "source": [
    "## list -> tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2110ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before modify: tensor([1, 1, 1]) torch.int64\n",
      "Before modify: tensor([1, 1, 1]) torch.int64\n",
      "Before modify: tensor([1., 1., 1.]) torch.float32\n",
      "After modify: tensor([1, 1, 1]) torch.int64\n",
      "After modify: tensor([1, 1, 1]) torch.int64\n",
      "After modify: tensor([1., 1., 1.]) torch.float32\n"
     ]
    }
   ],
   "source": [
    "list_1 = [1,1,1]\n",
    "\n",
    "list2tensor_1 = torch.as_tensor(list_1)   # 深拷贝, 保留原数据类型\n",
    "list2tensor_2 = torch.tensor(list_1)      # 深拷贝, 保留原数据类型\n",
    "list2tensor_3 = torch.Tensor(list_1)      # 深拷贝, 保存为float\n",
    "\n",
    "print('Before modify:', list2tensor_1, list2tensor_1.dtype)\n",
    "print('Before modify:', list2tensor_2, list2tensor_2.dtype)\n",
    "print('Before modify:', list2tensor_3, list2tensor_3.dtype)\n",
    "\n",
    "list_1[1] = 2\n",
    "print('After modify:', list2tensor_1, list2tensor_1.dtype)\n",
    "print('After modify:', list2tensor_2, list2tensor_2.dtype)\n",
    "print('After modify:', list2tensor_3, list2tensor_3.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9381bb2a",
   "metadata": {},
   "source": [
    "## torch.tensor(data, *, dtype=None, device=None, requires_grad=False, pin_memory=False)\n",
    "Data type                | dtype                         | Legacy Constructors\n",
    ":- | :- | :-\n",
    "32-bit floating point    | torch.float32 or torch.float  | torch.*.FloatTensor\n",
    "64-bit floating point    | torch.float64 or torch.double | torch.*.DoubleTensor\n",
    "64-bit complex           | torch.complex64 or torch.cfloat\n",
    "128-bit complex          | torch.complex128 or torch.cdouble\n",
    "16-bit floating point 1  | torch.float16 or torch.half   | torch.*.HalfTensor\n",
    "16-bit floating point 2  | torch.bfloat16                | torch.*.BFloat16Tensor\n",
    "8-bit integer (unsigned) | torch.uint8                   | torch.*.ByteTensor\n",
    "8-bit integer (signed)   | torch.int8                    | torch.*.CharTensor\n",
    "16-bit integer (signed)  | torch.int16 or torch.short    | torch.*.ShortTensor\n",
    "32-bit integer (signed)  | torch.int32 or torch.int      | torch.*.IntTensor\n",
    "64-bit integer (signed)  | torch.int64 or torch.long     | torch.*.LongTensor\n",
    "Boolean                  | torch.bool                    | torch.*.BoolTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "27b100ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.],\n",
      "        [7., 8., 9.]])\n",
      "<class 'torch.Tensor'>\n",
      "is a tensor? True\n",
      "torch.float32\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "tensor1 = torch.tensor([[1,2,3],[4,5,6],[7,8,9]], dtype=torch.float)\n",
    "print(tensor1)\n",
    "print( type(tensor1) )\n",
    "print('is a tensor?', torch.is_tensor(tensor1) )\n",
    "print( tensor1.dtype )\n",
    "print( tensor1.device )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2321f7e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.+0.j]) is complex? True\n",
      "tensor([1.+0.j], dtype=torch.complex128) is complex? True\n",
      "tensor([1.]) is float? True\n",
      "tensor([1.], dtype=torch.float64) is float? True\n",
      "tensor([1.], dtype=torch.float16) is float? True\n",
      "tensor([1.], dtype=torch.bfloat16) is float? True\n"
     ]
    }
   ],
   "source": [
    "print(torch.tensor([1], dtype = torch.complex64), 'is complex?', torch.is_complex(torch.tensor([1], dtype = torch.complex64)))\n",
    "print(torch.tensor([1], dtype = torch.complex128), 'is complex?', torch.is_complex(torch.tensor([1], dtype = torch.complex128)))\n",
    "print(torch.tensor([1], dtype = torch.float32), 'is float?', torch.is_floating_point(torch.tensor([1], dtype = torch.float32)))\n",
    "print(torch.tensor([1], dtype = torch.float64), 'is float?', torch.is_floating_point(torch.tensor([1], dtype = torch.float64)))\n",
    "print(torch.tensor([1], dtype = torch.float16), 'is float?', torch.is_floating_point(torch.tensor([1], dtype = torch.float16)))\n",
    "print(torch.tensor([1], dtype = torch.bfloat16), 'is float?', torch.is_floating_point(torch.tensor([1], dtype = torch.bfloat16)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617a100b",
   "metadata": {},
   "source": [
    "# 生成操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abf667f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_1 = torch.tensor([[1,2,3],[4,5,6],[7,8,9]], dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d08967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.基本\n",
    "\"\"\"\n",
    "torch.zeros(*size, *, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False)\n",
    "\"\"\"\n",
    "print( torch.zeros(5, 3) )\n",
    "print( '<=>', torch.zeros((5,3)) )\n",
    "\"\"\"\n",
    "torch.zeros_like(input, *, dtype=None, layout=None, device=None, requires_grad=False, memory_format=torch.preserve_format)\n",
    "\"\"\"\n",
    "print( torch.zeros_like(tensor1) )\n",
    "\"\"\"\n",
    "torch.ones(*size, *, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False)\n",
    "\"\"\"\n",
    "print( torch.ones(5, 3) )\n",
    "\"\"\"\n",
    "torch.ones_like(input, *, dtype=None, layout=None, device=None, requires_grad=False, memory_format=torch.preserve_format)\n",
    "\"\"\"\n",
    "print( torch.ones_like(tensor1) )\n",
    "\"\"\"\n",
    "torch.eye(n, m=None, *, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False)\n",
    "对角线为1\n",
    "\"\"\"\n",
    "print( torch.eye(5, 3) )\n",
    "\"\"\"\n",
    "torch.empty(*size, *, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False, pin_memory=False) \n",
    "生成一个空的tensor(每个元素为随机的极其小的正值，从而不影响数值计算）\n",
    "\"\"\"\n",
    "print( torch.empty(5, 3) )\n",
    "\"\"\"\n",
    "torch.empty_like(input, *, dtype=None, layout=None, device=None, requires_grad=False, memory_format=torch.preserve_format)\n",
    "\"\"\"\n",
    "print( torch.empty_like(tensor1) )\n",
    "\"\"\"\n",
    "torch.full(size, fill_value, *, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False)\n",
    "Creates a tensor of size size filled with fill_value\n",
    "\"\"\"\n",
    "print( torch.full(size=(2, 3), fill_value=3.141592) )\n",
    "\"\"\"\n",
    "torch.full_like(input, fill_value, *, dtype=None, layout=torch.strided, device=None, requires_grad=False, memory_format=torch.preserve_format)\n",
    "Creates a tensor of size size filled with fill_value\n",
    "\"\"\"\n",
    "print( torch.full_like(tensor1, fill_value=3.141592) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfe1af0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de4ebfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b66d96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
