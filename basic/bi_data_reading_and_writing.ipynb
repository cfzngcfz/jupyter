{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07268956",
   "metadata": {},
   "source": [
    "# cpp 读写\n",
    "参考:  \n",
    "https://en.cppreference.com/w/cpp/io/basic_ifstream  \n",
    "https://en.cppreference.com/w/cpp/io/basic_ifstream/open  \n",
    "https://en.cppreference.com/w/cpp/io/basic_istream/getline  \n",
    "https://www.runoob.com/cplusplus/cpp-files-streams.html  \n",
    "https://www.cnblogs.com/ZY-Dream/p/11181924.html  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26707c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <iostream> //控制台输入输出 cin, cout\n",
    "#include <fstream>  //文件输入输出\n",
    "#include <sstream>\n",
    "#include <string>\n",
    "#include <vector>\n",
    "using namespace std;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d668259",
   "metadata": {},
   "source": [
    "## cpp 写入 txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e297de06",
   "metadata": {},
   "outputs": [],
   "source": [
    "string filename = \"./temp/data_cpp.txt\";\n",
    "ofstream fs;\n",
    "//fs.open(filename, ios::out); // open for writing\n",
    "//fs.open(filename, ios::app); // seek to the end of stream before each write 追加\n",
    "fs.open(filename, ios::trunc); // discard the contents of the stream when opening 清空原有内容\n",
    "//fs.open(filename, ios::ate); // seek to the end of stream immediately after open \n",
    "//fs.open(filename, ios::binary); // open in binary mode\n",
    "\n",
    "\n",
    "fs << \"name,age,hobby\" << endl;\n",
    "fs << \"Mike,18,paiting\" << endl;\n",
    "fs << \"Tom,25,football\" << endl;\n",
    "fs << \"Jack,21,music\" << endl;\n",
    "fs.close();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92fbdab2",
   "metadata": {},
   "source": [
    "## cpp 读取 txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abe09484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "name,age,hobby\n",
      "name = name; age = age; hobby = hobby\n",
      "\n",
      "Mike,18,paiting\n",
      "name = Mike; age = 18; hobby = paiting\n",
      "\n",
      "Tom,25,football\n",
      "name = Tom; age = 25; hobby = football\n",
      "\n",
      "Jack,21,music\n",
      "name = Jack; age = 21; hobby = music\n"
     ]
    }
   ],
   "source": [
    "string filename = \"./temp/data_cpp.txt\";\n",
    "ifstream fs;\n",
    "fs.open(filename, ios::in); // open for reading\n",
    "if(fs.is_open()) //checks if the stream has an associated file\n",
    "{\n",
    "    string line; // 记录行\n",
    "    string name, age, hobby; // 记录每行中的元素\n",
    "    while(getline(fs, line) && fs.good()) {\n",
    "        cout << \"\\n\" << line << endl;\n",
    "        \n",
    "        // 读取当前行的每个元素\n",
    "        stringstream ss(line);\n",
    "        getline(ss, name, ',');\n",
    "        getline(ss, age, ',');\n",
    "        getline(ss, hobby, ',');\n",
    "        cout << \"name = \" << name << \"; age = \" << age << \"; hobby = \" << hobby << endl;\n",
    "    }\n",
    "    fs.close();\n",
    "}\n",
    "else {\n",
    "    cout << filename << \" cannot open!\" << endl;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6fd1222",
   "metadata": {},
   "source": [
    "## cpp 写入 csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "279a4133",
   "metadata": {},
   "outputs": [],
   "source": [
    "string filename = \"./temp/data_cpp.csv\";\n",
    "ofstream fs;\n",
    "fs.open(filename, ios::out); // open for writing\n",
    "fs << \"name\" << ',' << \"age\" << ',' << \"hobby\" << endl;\n",
    "fs << \"Mike\" << ',' << 18 << ',' << \"paiting\" << endl;\n",
    "fs << \"Tom\" << ',' << 25 << ',' << \"football\" << endl;\n",
    "fs << \"Jack\" << ',' << 21 << ',' << \"music\" << endl;\n",
    "fs.close();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c0686a",
   "metadata": {},
   "source": [
    "## cpp 读取 csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6a4e652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "name,age,hobby\n",
      "name | age | hobby | \n",
      "\n",
      "Mike,18,paiting\n",
      "Mike | 18 | paiting | \n",
      "\n",
      "Tom,25,football\n",
      "Tom | 25 | football | \n",
      "\n",
      "Jack,21,music\n",
      "Jack | 21 | music | \n"
     ]
    }
   ],
   "source": [
    "string filename = \"./temp/data_cpp.csv\";\n",
    "ifstream fs;\n",
    "fs.open(filename, ios::in); // open for reading\n",
    "if(fs.is_open()) //checks if the stream has an associated file\n",
    "{\n",
    "    string line;\n",
    "    while(getline(fs, line) && fs.good()) {\n",
    "        cout << \"\\n\" << line << endl;\n",
    "        \n",
    "        // 读取当前行的每个cell\n",
    "        stringstream ss(line);\n",
    "        string str;\n",
    "        while (getline(ss, str, ',')) {\n",
    "            cout << str << \" | \";\n",
    "        }\n",
    "        cout << endl;\n",
    "    }\n",
    "    fs.close();\n",
    "}\n",
    "else {\n",
    "    cout << filename << \" cannot open!\" << endl;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fdab980d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name,age,hobby\n",
      "Mike,18,paiting\n",
      "Tom,25,football\n",
      "Jack,21,music\n"
     ]
    }
   ],
   "source": [
    "string filename = \"./temp/data_cpp.csv\";\n",
    "ifstream fs;\n",
    "fs.open(filename, ios::in);\n",
    "if(fs.is_open()) //checks if the stream has an associated file\n",
    "{\n",
    "    for (std::string line; std::getline(fs, line); ) {\n",
    "        std::cout << line << '\\n';\n",
    "    }\n",
    "}\n",
    "else {\n",
    "    cout << filename << \" cannot open!\" << endl;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd5f9bb",
   "metadata": {},
   "source": [
    "## 控制台的输入cin和输出cout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c60208b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is your name?\n",
      "cc\n",
      "Hello cc, nice to meet you.\n"
     ]
    }
   ],
   "source": [
    "std::string name;\n",
    "std::cout << \"What is your name?\\n\";\n",
    "std::getline(std::cin, name);\n",
    "std::cout << \"Hello \" << name << \", nice to meet you.\\n\";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026c7c74",
   "metadata": {},
   "source": [
    "## 其他"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "22cfaff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The sum is: 28\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// read file line by line\n",
    "std::istringstream input;\n",
    "input.str(\"1\\n2\\n3\\n4\\n5\\n6\\n7\\n\");\n",
    "int sum = 0;\n",
    "for (std::string line; std::getline(input, line); ) {\n",
    "    sum += std::stoi(line);\n",
    "}\n",
    "std::cout << \"\\nThe sum is: \" << sum << \"\\n\\n\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f176452d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "b\n",
      "c\n",
      "d\n"
     ]
    }
   ],
   "source": [
    "std::istringstream input2;\n",
    "input2.str(\"a;b;c;d\");\n",
    "for (std::string line; std::getline(input2, line, ';'); ) {\n",
    "    std::cout << line << '\\n';\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68350dd",
   "metadata": {},
   "source": [
    "# python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc38ac30",
   "metadata": {},
   "source": [
    "## txt读写\n",
    "### 写入 txt\n",
    "符号|路径表示\n",
    ":-|:-\n",
    "'.'|当前文件夹\n",
    "\"..\"|上一级文件夹  \n",
    "'/'|相对路径\n",
    "'\\\\'|绝对路径;  \n",
    " \n",
    "\n",
    "符号 | 读写模式 | 指针位置  \n",
    ":-|:-|:-  \n",
    "r   | 以只读模式打开 | 如果同名文件已存在，指针(输入位置)放在文件开头；如果同名文件不存在，报错  \n",
    "rb  | 以二进制+只读模式打开 | 同 r  \n",
    "r+  | 以读写模式打开 | 既可以从开头读取文件内容，也可以从开头向同名文件写入新内容，并覆盖该文件中等长度的原有内容  \n",
    "rb+ | 以二进制+读写模式打开 | 同 r  \n",
    "w | 以只写模式打开 | 如果同名文件已存在，则打开该文件，删除原有内容，并从开头重新编辑；如果同名文件不存在，则创建新文件，指针放在文件开头。  \n",
    "wb | 以二进制+只写模式打开 | 同 w  \n",
    "w+ | 以读写模式打开 | 同 w  \n",
    "wb+ | 以二进制+读写模式打开 | 同 w  \n",
    "a | 以只写+追加模式打开 | 如果同名文件已存在，则指针放于文件末尾，即在原有内容之后继续写入新内容;如果同名文件不存在，则创建新文件，然后写入。  \n",
    "ab | 以二进制+只写+追加模式打开 | 同 a  \n",
    "a+ | 以读写+追加模式打开 | 同 a  \n",
    "ab+ | 以二进制+读写+追加模式打开 | 同 a  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0c5f3727",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_A = [[\"The Fast and the Furious\", 2001],\n",
    "          #[\"2 Fast 2 Furious\", 2003],\n",
    "          #[\"The Fast and the Furious: Tokyo Drift\", 2006],\n",
    "          #[\"Fast & Furious\", 2009],\n",
    "          #[\"Fast Five\", 2011],\n",
    "          #[\"Fast & Furious 6\", 2013],\n",
    "          #[\"Fast & Furious 7\", 2015],\n",
    "          #[\"The Fate of the Furious\", 2017],\n",
    "          #[\"Hobbs and Shaw\", 2019],\n",
    "          [\"Fast & Furious 9\", 2021]         ]\n",
    "movies_B = [[\"Transformers\", 2007],\n",
    "          #[\"Transformers:Revenge of the Fallen\", 2009],\n",
    "          #[\"Transformers: Dark of the Moon\", 2011],\n",
    "          #[\"Transformers: Age of Extinction\", 2014],\n",
    "          #[\"Transformers: The Last Knight\", 2017],\n",
    "          [\"Bumblebee\", 2018]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2c68dc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./output/test01.txt\"\n",
    "with open(path, 'w', encoding=\"utf-8\") as file:\n",
    "    for row in movies_A:\n",
    "        file.write( ', '.join([row[0], str(row[1])]) ) #仅支持字符型数据写入\n",
    "        file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2f6c97f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./output/test02.txt\"\n",
    "file = open(path, 'a', encoding=\"utf-8\")\n",
    "for row in movies_B:\n",
    "    file.write( ', '.join([row[0], str(row[1])]) )\n",
    "    file.write('\\n')\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4991a2",
   "metadata": {},
   "source": [
    "### 读取 txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4b8249e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Fast and the Furious, 2001\n",
      "\n",
      "Fast & Furious 9, 2021\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "path = \"./output/test01.txt\"\n",
    "if os.path.exists(path):\n",
    "    with open(path, 'r', encoding=\"utf-8\") as file:\n",
    "        rows = file.readlines()\n",
    "        for row in rows:\n",
    "            print(row)\n",
    "else:\n",
    "    print(path,\"不存在\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8a8172b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./output/test03.txt 不存在\n"
     ]
    }
   ],
   "source": [
    "path = \"./output/test03.txt\"\n",
    "if os.path.exists(path):\n",
    "    file_txt = open(path, 'r', encoding=\"utf-8\")\n",
    "    rows = file_txt.readlines()  \n",
    "    for row in rows:\n",
    "        print(row)\n",
    "    file_txt.close()\n",
    "else:\n",
    "    print(path,\"不存在\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff48da1",
   "metadata": {},
   "source": [
    "## csv读写\n",
    "https://docs.python.org/zh-cn/3/library/csv.html  \n",
    "https://docs.python.org/3/library/csv.html  \n",
    "There is only one \"sheet\" and data is separated by a delimiter (typically a comma) with newlines separating rows.  \n",
    "\n",
    "### 逐行写入 csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bd05751f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "path = \"./output/test01.csv\"\n",
    "header = [\"name\", \"year\"]\n",
    "with open(path, 'w', newline='', encoding=\"utf-8\") as file: # 默认encoding='gbk'\n",
    "    spreadsheet = csv.writer(file, delimiter=',')\n",
    "        # default delimiter=',' --> 分隔符为,\n",
    "        # delimiter='\\t' --> 分隔符为tab\n",
    "    spreadsheet.writerow(header) \n",
    "    for row in movies_A:\n",
    "        spreadsheet.writerow(row) #待写入的对象为list，并自动将int or float转成str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049c1583",
   "metadata": {},
   "source": [
    "### 多行写入 csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e4a28bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2.写入2-多行写入\n",
    "path = \"./output/test01.csv\"\n",
    "file = open(path, 'a', newline='', encoding='utf-8')\n",
    "spreadsheet = csv.writer(file)\n",
    "spreadsheet.writerows([row for row in movies_B])\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d44f42",
   "metadata": {},
   "source": [
    "### 读取 csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b3ba0898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first line: ['name', 'year']\n",
      "2 ['The Fast and the Furious', '2001']\n",
      "3 ['Fast & Furious 9', '2021']\n",
      "4 ['Transformers', '2007']\n",
      "5 ['Bumblebee', '2018']\n"
     ]
    }
   ],
   "source": [
    "path = \"./output/test01.csv\"\n",
    "if os.path.exists(path):\n",
    "    with open(path, 'r', newline='', encoding='utf-8') as file:\n",
    "        spreadsheet = csv.reader(file)\n",
    "        print(\"first line:\", next(spreadsheet)) # next()获取可迭代对象(spreadsheet)的下一行，此处为第一行\n",
    "        for row in spreadsheet:                 # 由于spreadsheet只能被遍历一次，所以此时spreadsheet从第二行开始\n",
    "            print(spreadsheet.line_num, row) \n",
    "else:\n",
    "    print(path,\"不存在\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bdd2534b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 ['The Fast and the Furious', '2001']\n",
      "3 ['Fast & Furious 9', '2021']\n",
      "4 ['Transformers', '2007']\n",
      "5 ['Bumblebee', '2018']\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(path):\n",
    "    file = open(path, 'r', newline='', encoding='utf-8')\n",
    "    spreadsheet = csv.reader(file)\n",
    "    for row in spreadsheet:\n",
    "        if spreadsheet.line_num == 1: # 忽略表头\n",
    "            continue\n",
    "        else:\n",
    "            print(spreadsheet.line_num, row)\n",
    "    file.close()\n",
    "else:\n",
    "    print(path,\"不存在\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c23cfa",
   "metadata": {},
   "source": [
    "### csv 写入 dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8786565c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./output/test02.csv\"\n",
    "header = [\"name\", \"year\"]\n",
    "\n",
    "file = open(path, 'w', newline='', encoding='utf-8')\n",
    "spreadsheet = csv.DictWriter(file, header)\n",
    "spreadsheet.writeheader() #自动写入表头\n",
    "spreadsheet.writerow({'name': 'a', 'year': '2019'})\n",
    "spreadsheet.writerow({'name': 'b', 'year': '2021'})\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89103d0c",
   "metadata": {},
   "source": [
    "### csv 读取 dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "29d361c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "header: ['name', 'year']\n",
      "{'name': 'a', 'year': '2019'}\n",
      "a\n",
      "{'name': 'b', 'year': '2021'}\n",
      "b\n"
     ]
    }
   ],
   "source": [
    "with open(path, 'r', newline='', encoding='utf-8') as file:\n",
    "    spreadsheet = csv.DictReader(file)\n",
    "    print(\"header:\",spreadsheet.fieldnames)\n",
    "    for row in spreadsheet:\n",
    "        print(row)\n",
    "        print(row['name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5206591b",
   "metadata": {},
   "source": [
    "## xlsx读写(待细化)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9262afdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "from openpyxl.utils import get_column_letter\n",
    "num_col = 26*27+1\n",
    "print('第',num_col,'列的大写英文字符 -->', get_column_letter(num_col) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a8d552",
   "metadata": {},
   "source": [
    "### 写入 xlsx - one sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604e35e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "workbook = openpyxl.Workbook()\n",
    "worksheet01 = workbook.active  # activate default sheet\n",
    "# worksheet01 = workbook.create_sheet(title='A') # create a new sheet after default sheet, activate this sheet and rename its tag name to 'A'\n",
    "# 等价于\n",
    "# worksheet01 = workbook.create_sheet()\n",
    "# worksheet01.title = 'A'\n",
    "worksheet01['A1'] = '城市' #一个单元格写入方法1\n",
    "worksheet01['B1'] = 'number'\n",
    "worksheet01.cell(row=1, column=3).value = '城市' #一个单元格写入方法2\n",
    "worksheet01.cell(row=1, column=4).value = 'number'\n",
    "for ii in range(len(data01)):\n",
    "    worksheet01.append(data01[ii]) # 一行单元格写入方法 (Add a new row at bottom)\n",
    "for row in range(2,4):\n",
    "    for col in range(3,5):\n",
    "        worksheet01.cell(row=row, column=col, value=get_column_letter(col)) #一个单元格写入方法3\n",
    "workbook.save('./test/b1.xlsx') # Write to disk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e64e67",
   "metadata": {},
   "source": [
    "### 写入 xlsx - multiple sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eeb90b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "workbook = openpyxl.Workbook()\n",
    "# sheet A\n",
    "worksheet01 = workbook.active #激活第一个sheet，如果该sheet已有内容，则将被覆盖，即sheet A替代了sheet C\n",
    "worksheet01.title = 'A'\n",
    "for ii in range(len(data01)):\n",
    "    for jj in range(len(data01[0])):\n",
    "        worksheet01.cell(ii+1, jj+1, data01[ii][jj])\n",
    "# sheet C\n",
    "worksheet03 = workbook.create_sheet(title='C', index=0) # 在第一位插入 标签为 C 的新sheet\n",
    "worksheet03.append(['广州', 1])\n",
    "worksheet03.append(['深圳', 23])\n",
    "# sheet B\n",
    "worksheet02 = workbook.create_sheet(title='B') #在已有sheet之后，添加新sheet\n",
    "for ii in range(len(data02)):\n",
    "    for jj in range(len(data02[0])):\n",
    "        worksheet02.cell(ii+1, jj+1, data02[ii][jj])\n",
    "# sheet D\n",
    "worksheet04 = workbook.create_sheet(title='D', index=-2) # 在最后一个sheet的前2个位置(倒数第三个位置)插入 标签为 D 的新sheet\n",
    "worksheet04.append(['杭州', 1])\n",
    "worksheet04.append(['宁波', 23])\n",
    "workbook.save('./test/b2.xlsx') #最终保存顺序: C -> D -> A -> B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2ab4df",
   "metadata": {},
   "source": [
    "### 读取 xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5e09bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "workbook = openpyxl.load_workbook('./test/b1.xlsx')\n",
    "# workbook = openpyxl.load_workbook('./test/aa.xlsx', read_only=True) # 只读模式，读取速度更快\n",
    "print('name of all sheets:', workbook.sheetnames) # List sheets available\n",
    "worksheet_current = workbook.worksheets[0] #第一个sheet\n",
    "# 等价于 worksheet_current = workbook['E']\n",
    "print('sheet tab name:',worksheet_current.title)\n",
    "print('范围:',worksheet_current.dimensions)\n",
    "print('min_row:',worksheet_current.min_row)\n",
    "print('max_row:',worksheet_current.max_row)\n",
    "print('min_column:',worksheet_current.min_column)\n",
    "print('max_column:',worksheet_current.max_column)\n",
    "# 3.3.1.读取一个单元格\n",
    "print(worksheet_current['B2'].value,\n",
    "      worksheet_current['B2'].value == worksheet_current.cell(row=2, column=2).value )\n",
    "print('坐标:', worksheet_current['B2'].coordinate)\n",
    "print('行:', worksheet_current['B2'].row)\n",
    "print('列:', worksheet_current['B2'].column)\n",
    "# 3.3.2.遍历 指定区域或所有 单元格\n",
    "# 3.3.2.1.xlsx --> list \n",
    "data03 = []\n",
    "for row in worksheet_current.rows:\n",
    "    temp = [cell.value for cell in row]\n",
    "    data03.append(temp)\n",
    "print(data03)\n",
    "# 3.3.2.2.按行遍历\n",
    "for row in worksheet_current.rows:\n",
    "    for cell in row:\n",
    "        print(cell.value)\n",
    "for row in worksheet_current.values:\n",
    "    for value in row:\n",
    "        print(value)\n",
    "for row in worksheet_current.iter_rows(min_row=1,max_row=2,min_col=1,max_col=2): #指定区域\n",
    "    for cell in row:\n",
    "        print(cell.value)\n",
    "for row in worksheet_current.iter_rows(min_row=1,max_row=2,min_col=1,max_col=2, values_only=True ): #指定区域\n",
    "    for value in row:\n",
    "        print(value)\n",
    "# 3.3.2.3.按列遍历（不支持 read_only=True）\n",
    "for column in worksheet_current.columns:\n",
    "    for cell in column:\n",
    "        print(cell.value)\n",
    "for row in worksheet_current.iter_cols(min_row=1,max_row=2,min_col=1,max_col=2): #指定区域\n",
    "    for cell in row:\n",
    "        print(cell.value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded01b09",
   "metadata": {},
   "source": [
    "### 读取 -> 修改 -> 保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad630249",
   "metadata": {},
   "outputs": [],
   "source": [
    "workbook = openpyxl.load_workbook('./test/b1.xlsx')\n",
    "worksheet_current = workbook.active\n",
    "print(worksheet_current['D4'].value) #读取\n",
    "worksheet_current.cell(row=4, column=4, value=81.64) #修改\n",
    "print(worksheet_current['D4'].value)\n",
    "workbook.save('./test/b1.xlsx') #保存"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e82b79",
   "metadata": {},
   "source": [
    "##  xls读写(待细化)\n",
    "###  写入 xls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156e3c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xlwt\n",
    "# https://blog.csdn.net/sinat_28576553/article/details/81275650#5%E3%80%81%E4%BF%AE%E6%94%B9%E5%B7%B2%E7%BB%8F%E5%AD%98%E5%9C%A8%E7%9A%84%E5%B7%A5%E4%BD%9C%E7%B0%BF(%E8%A1%A8)\n",
    "\n",
    "\n",
    "workbook1 = xlwt.Workbook(encoding='utf-8') #注意Workbook的开头W要大写\n",
    "sheet1 = workbook1.add_sheet('list01', cell_overwrite_ok=True) # cell_overwrite_ok=True：覆盖原单元格数据\n",
    "for xx in range(len(list01)):\n",
    "    for yy in range(len(list01[0])):\n",
    "        sheet1.write( xx, yy, data01[xx][yy] )\n",
    "workbook1.save('./test/list01.xls') # 保存该excel文件,有同名文件时直接覆盖；只能保存为xls，不能保存为xlsx\n",
    "print('list01:保存至excel!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f4dd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xlwt\n",
    "workbook1 = xlwt.Workbook() #注意Workbook的开头W要大写\n",
    "sheet1 = workbook1.add_sheet('data',cell_overwrite_ok=True)\n",
    "for xx in range(len(Results)):\n",
    "    for yy in range(len(Results[0])):\n",
    "        sheet1.write(yy,xx,Results[xx][yy])#这些列用于记录每年独立专利数\n",
    "#保存该excel文件,有同名文件时直接覆盖\n",
    "workbook1.save('data.xls')\n",
    "print('保存excel完毕!')      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf0c606",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xlwt\n",
    "workbook1 = xlwt.Workbook() #注意Workbook的开头W要大写\n",
    "#sheet1 = workbook1.add_sheet('data',cell_overwrite_ok=True)\n",
    "sheet1 = workbook1.sheet_by_index(0)\n",
    "for xx in range(len(records)):\n",
    "    for yy in range(len(records[0])):\n",
    "        sheet1.write(yy+1+label*10,xx,records[xx][yy])#这些列用于记录每年独立专利数\n",
    "#保存该excel文件,有同名文件时直接覆盖\n",
    "workbook1.save('data.xls')\n",
    "print('保存excel完毕!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39889c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xlwt\n",
    "workbook3 = xlwt.Workbook() #注意Workbook的开头W要大写\n",
    "sheet3 = workbook3.add_sheet('statistics',cell_overwrite_ok=True)\n",
    "for jj in range(unique_Date[-1]-unique_Date[0]+1):\n",
    "    sheet3.write(0,jj+1,jj+unique_Date[0])#这些列用于记录每年独立专利数\n",
    "    sheet3.write(0,jj+1+unique_Date[-1]-unique_Date[0]+1,jj+unique_Date[0])#这些列用于记录每年合作专利数\n",
    "sheet3.write(0,(unique_Date[-1]-unique_Date[0]+1)*2+1,'all_single')#用于记录每年独立专利数\n",
    "sheet3.write(0,(unique_Date[-1]-unique_Date[0]+1)*2+2,'all_cooperation')#用于记录每年独立专利数\n",
    "sheet3.write(0,(unique_Date[-1]-unique_Date[0]+1)*2+3,'all')#用于记录每年独立专利数\n",
    "for ii in range(len(unique_DWPI)):\n",
    "    sheet3.write(ii+1,0,unique_DWPI[ii])#写入一列，用于记录不重复的所有专利\n",
    "for ii in range(len(unique_DWPI)):\n",
    "    for jj in range((unique_Date[-1]-unique_Date[0]+1)*2):\n",
    "        sheet3.write(ii+1,jj+1,statistics[ii][jj])#保存statistics\n",
    "    sheet3.write(ii+1,(unique_Date[-1]-unique_Date[0]+1)*2+1,sum(statistics[ii][0:unique_Date[-1]-unique_Date[0]+1]))#统计某专利历年的独立数量\n",
    "    sheet3.write(ii+1,(unique_Date[-1]-unique_Date[0]+1)*2+2,sum(statistics[ii][unique_Date[-1]-unique_Date[0]+1:(unique_Date[-1]-unique_Date[0]+1)*2]))#统计某专利历年的合作数量\n",
    "    sheet3.write(ii+1,(unique_Date[-1]-unique_Date[0]+1)*2+3,sum(statistics[ii][0:(unique_Date[-1]-unique_Date[0]+1)*2]))#统计某专利历年的总数量\n",
    "#保存该excel文件,有同名文件时直接覆盖\n",
    "workbook3.save('statistics.xls')\n",
    "print('保存excel完毕!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a4c7a8",
   "metadata": {},
   "source": [
    "### 读取 xls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e64b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xlrd\n",
    "# 打开Excel文件\n",
    "workbook2 = xlrd.open_workbook('./test/list01.xls')\n",
    "## 根据sheet索引或者名称获取sheet内容\n",
    "#sheet2 = workbook2.sheets()[0]              # 通过索引顺序获取\n",
    "#sheet3 = workbook2.sheet_by_index(0)        # 通过索引顺序获取\n",
    "#sheet4 = workbook2.sheet_by_name('list01')  # 通过名称获取\n",
    "## sheet对象的基本属性：名称，行数，列数等：\n",
    "#print('sheet名称:',sheet2.name,';行数:',sheet2.nrows,';列数:',sheet2.ncols)\n",
    "## 获取整行和整列的值（数组）：\n",
    "#row = sheet2.row_values(0) # 获取第1行内容\n",
    "#print(row)\n",
    "#col = sheet2.col_values(1) # 获取第2列内容\n",
    "#print(col)\n",
    "## 获取单元格内容：\n",
    "#print(sheet2.cell(1,0).value)\n",
    "#print(sheet2.cell_value(1,0))\n",
    "#print(sheet2.row(1)[0].value)\n",
    "sheet2 = workbook2.sheets()[0] # 通过索引顺序获取\n",
    "data02 = []\n",
    "for ii in range(sheet2.nrows):\n",
    "    data02.append(sheet2.row_values(ii))\n",
    "print(data02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af47a306",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xlrd\n",
    "##获取Excel：\n",
    "workbook1 = xlrd.open_workbook(\"2012.xlsx\")\n",
    "#print('sheet_names:',workbook1.sheet_names())      # 获取所有sheet名字\n",
    "#print('sheet_number:',workbook1.nsheets)           # 获取sheet数量\n",
    "#print('sheet_object:',workbook1.sheets())          # 获取所有sheet对象\n",
    "#print('By_name:',workbook1.sheet_by_name(\"Sheet1\"))# 通过sheet名查找\n",
    "#print('By_index:',workbook1.sheet_by_index(0))     # 通过索引查找\n",
    "##读取sheet:\n",
    "sheet1=workbook1.sheet_by_index(0)  # 读取第一个sheet\n",
    "##sheet1=workbook1.sheets()[0]        # 读取第一个sheet\n",
    "#print('sheet name:',sheet1.name)    # 获取sheet名\n",
    "#print('row num:',sheet1.nrows)      # 获取总行数\n",
    "#print('col num:',sheet1.ncols)      # 获取总列数\n",
    "##行数据读取:\n",
    "#print(sheet1.row_values(1))         # 获取第一行所有内容，合并单元格，首行显示值，其它为空。\n",
    "#print(sheet1.row(1))                # 获取单元格值类型和内容\n",
    "#print(sheet1.row_types(1))          # 获取单元格数据类型\n",
    "##特定区域的数据读取:\n",
    "#print(sheet1.row_values(1)[:2])     # 第1行前2列\n",
    "#print(sheet1.row_values(1,0,2))     # 取第1行，第1~3列（不含第3列） row_values(1行,0列,2列)\n",
    "#print(sheet1.col_values(1,1,6))     # 取第2列，第1~6行（不含第6行） col_values(1列,1行,6行)\n",
    "#print(sheet1.row_slice(2,0,2))      # 获取单元格值类型和内容\n",
    "#print(sheet1.row_types(1,0,2))      # 获取单元格数据类型\n",
    "##特定单元格读取:\n",
    "#print(sheet1.cell_value(1,1))       # 第2行第2列的数据\n",
    "#print(sheet1.cell_value(1,1).encode('utf-8'))\n",
    "#print(sheet1.cell(1,1).value)       # 第2行第2列的数据\n",
    "#print(sheet1.cell(1,1).value.encode('utf-8'))\n",
    "#print(sheet1.row(1)[1].value)       # 第2行第2列的数据\n",
    "#print(sheet1.row(1)[1].value.encode('utf-8'))\n",
    "#print(sheet1.cell(1,1).ctype)       # 第2行第2列的数据类型\n",
    "#print(sheet1.cell_type(1,1))        # 第2行第2列的数据类型\n",
    "#print(sheet1.row(1)[1].ctype)       # 第2行第2列的数据类型\n",
    "##数据类型:空-0;字符串-1;数字-2;日期-3;布尔-4;error-5\n",
    "##矩阵坐标转换为Excel的坐标\n",
    "#print(xlrd.cellname(1,1))           # (1,1)转换成B2\n",
    "#print(xlrd.cellnameabs(1,2))        # (1,2)转换成$C$2\n",
    "#print(xlrd.colname(30))             # 把列由数字转换为字母表示\n",
    "workbook2 = xlrd.open_workbook(\"2013.xlsx\")\n",
    "sheet2=workbook2.sheet_by_index(0)  #读取第一个sheet\n",
    "#两个表的数据整合\n",
    "data=[]\n",
    "for ii in range(sheet1.nrows):\n",
    "    if ii!=0:\n",
    "        data.append(sheet1.row_values(ii))\n",
    "for ii in range(sheet2.nrows):\n",
    "    if ii!=0:\n",
    "        data.append(sheet2.row_values(ii))\n",
    "##验证表头是否一致，如果一致则输出表头\n",
    "#if sheet1.row_values(0)==sheet2.row_values(0):\n",
    "#    print(sheet1.row_values(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd96a120",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xlrd\n",
    "# 打开Excel文件\n",
    "workbook = xlrd.open_workbook(path_excel)\n",
    "list_sheet = workbook.sheet_names()\n",
    "for ii in range(len(list_sheet)):\n",
    "    worksheet_current = workbook.sheet_by_index(ii)\n",
    "    ## 根据sheet索引或者名称获取sheet内容\n",
    "    #sheet2 = workbook2.sheets()[0]              # 通过索引顺序获取\n",
    "    #sheet3 = workbook2.sheet_by_index(0)        # 通过索引顺序获取\n",
    "    #sheet4 = workbook2.sheet_by_name('list01')  # 通过名称获取\n",
    "    # sheet对象的基本属性：名称，行数，列数等：\n",
    "    print('sheet名称:',worksheet_current.name,';行数:',worksheet_current.nrows,';列数:',worksheet_current.ncols)\n",
    "    ## 获取整行和整列的值（数组）：\n",
    "    #row = sheet2.row_values(0) # 获取第1行内容\n",
    "    #print(row)\n",
    "    #col = sheet2.col_values(1) # 获取第2列内容\n",
    "    #print(col)\n",
    "    ## 获取单元格内容：\n",
    "    #print(sheet2.cell(1,0).value)\n",
    "    #print(sheet2.cell_value(1,0))\n",
    "    #print(sheet2.row(1)[0].value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2660c789",
   "metadata": {},
   "source": [
    "## json读写\n",
    "\n",
    "命令|作用\n",
    ":-|:-\n",
    "json.dumps() | dict -> str\n",
    "json.loads() | str -> dict\n",
    "json.dump() | 将dict转成str，并写入json文件\n",
    "json.load() | 读取json文件中的str，并转成dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "72f6f5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "01f9e72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'a':1,'b':2,'c':3,'d':4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ad55d3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_str = json.dumps(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e2395f34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"a\": 1, \"b\": 2, \"c\": 3, \"d\": 4}'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9b4094c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_dict = json.loads(json_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0e140fbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 1, 'b': 2, 'c': 3, 'd': 4}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7d16ea",
   "metadata": {},
   "source": [
    "### 写入json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6ec343f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(json_dict, open('./output/test01.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c7099cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./output/test02.json', 'w') as file:  \n",
    "    file.write(json_str)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0124e469",
   "metadata": {},
   "source": [
    "### 读取json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b7adb879",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_dict2 = json.load(open('./output/test01.json', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "91d9b04b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 1, 'b': 2, 'c': 3, 'd': 4}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_dict2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbf31ad",
   "metadata": {},
   "source": [
    "## yaml读写"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3176d01f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apollo.ipynb\t\t\t\t    jupyter_20221001.ipynb\r\n",
      "Apollo_20220513.ipynb\t\t\t    leetcode\r\n",
      "Apollo_20220609.ipynb\t\t\t    note_ubuntu_20220628.ipynb\r\n",
      "Apollo_20220615.ipynb\t\t\t    note_wsl_20221126.ipynb\r\n",
      "Apollo_20220617.ipynb\t\t\t    opencv_data\r\n",
      "Apollo_20220628.ipynb\t\t\t    optimization_20221126.ipynb\r\n",
      "Atlas_20220805.ipynb\t\t\t    output\r\n",
      "bi_Math_20221126.ipynb\t\t\t    python_argparse_20221126.ipynb\r\n",
      "bi_bitwise_20221122.ipynb\t\t    python_datetime_20221126.ipynb\r\n",
      "bi_container_20221122.ipynb\t\t    python_enumerate_20221126.ipynb\r\n",
      "bi_data_reading_and_writing_20221204.ipynb  python_numpy_20221126.ipynb\r\n",
      "bi_mutil_thread_20221126.ipynb\t\t    python_osm_20221223.ipynb\r\n",
      "bi_string_20221122.ipynb\t\t    python_plot_20221126.ipynb\r\n",
      "bi_time_20221122.ipynb\t\t\t    python_proto_20221126.ipynb\r\n",
      "cpp_container_struct_20221126.ipynb\t    python_pyproj_20221126.ipynb\r\n",
      "cpp_eigen_20221126.ipynb\t\t    python_selenium_20221126.ipynb\r\n",
      "cpp_ptr_20221001.ipynb\t\t\t    python_shapely.ipynb\r\n",
      "cpp_vins_20221126.ipynb\t\t\t    routing_test_20220728.ipynb\r\n",
      "data\t\t\t\t\t    routing_test_old_20220628.ipynb\r\n",
      "jupyter_20220522.ipynb\t\t\t    test1.yaml\r\n",
      "jupyter_20220731.ipynb\t\t\t    test2.yaml\r\n",
      "jupyter_20220926.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f978753",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "data1 = {'page': 1,\n",
    " 'msg': '地址',\n",
    " 'data': [{'id': 1, 'name': '学校'},\n",
    "  {'id': 2, 'name': '公寓'},\n",
    "  {'id': 3, 'name': '流动人口社区'}]}\n",
    "\n",
    "data2 = {'page': 2,\n",
    " 'msg': '地址',\n",
    " 'data': [{'id': 1, 'name': '酒店'},\n",
    "  {'id': 2, 'name': '医院'},\n",
    "  {'id': 3, 'name': '养老院'}]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded7351a",
   "metadata": {},
   "source": [
    "### 写入yaml\n",
    "allow_unicode=True: 防止写入时中文乱码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6b9792e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 写入单个数据\n",
    "with open('./output/test1.yaml', 'w', encoding='utf-8') as f:\n",
    "    yaml.dump(data1, stream=f, allow_unicode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f32bb7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 写入多个数据\n",
    "with open('./output/test2.yaml', 'w', encoding='utf-8') as f:\n",
    "    yaml.dump_all([data1, data2], stream=f, allow_unicode=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f644a227",
   "metadata": {},
   "source": [
    "### 读取yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a19e675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': [{'id': 1, 'name': '学校'}, {'id': 2, 'name': '公寓'}, {'id': 3, 'name': '流动人口社区'}], 'msg': '地址', 'page': 1}\n"
     ]
    }
   ],
   "source": [
    "with open('./output/test1.yaml', 'r', encoding='utf-8') as f:\n",
    "    data = yaml.load(f, Loader=yaml.FullLoader)\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "22916bba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': [{'id': 1, 'name': '学校'}, {'id': 2, 'name': '公寓'}, {'id': 3, 'name': '流动人口社区'}], 'msg': '地址', 'page': 1}\n",
      "{'data': [{'id': 1, 'name': '酒店'}, {'id': 2, 'name': '医院'}, {'id': 3, 'name': '养老院'}], 'msg': '地址', 'page': 2}\n"
     ]
    }
   ],
   "source": [
    "with open('./output/test2.yaml', 'r', encoding='utf-8') as f:\n",
    "    Data = yaml.load_all(f, Loader=yaml.FullLoader)\n",
    "    for data in Data:\n",
    "        print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce19d9b4",
   "metadata": {},
   "source": [
    "## 读取本地文件夹/文件\n",
    "https://docs.python.org/zh-cn/3/library/os.html  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799bbddb",
   "metadata": {},
   "source": [
    "### 获取当前路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9593a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前路径: /mnt/d/github/jupyter/basic\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"当前路径:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0cd0463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前路径: /mnt/d/github/jupyter/basic\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(\"当前路径:\", sys.path[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4329da",
   "metadata": {},
   "source": [
    "### os.path\n",
    "https://docs.python.org/zh-cn/3/library/os.path.html#module-os.path  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "46d03d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "绝对路径: /code/jupyter/temp\n",
      "是否存在 True\n",
      "是否为目录: True\n",
      "是否为文件: False\n",
      "是否为绝对路径: False\n"
     ]
    }
   ],
   "source": [
    "path = \"./temp\"\n",
    "print(\"绝对路径:\",       os.path.abspath(path))\n",
    "print(\"是否存在\",        os.path.exists(path))\n",
    "print(\"是否为目录:\",     os.path.isdir(path))\n",
    "print(\"是否为文件:\",     os.path.isfile(path))\n",
    "print(\"是否为绝对路径:\", os.path.isabs(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "a905b577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096\n"
     ]
    }
   ],
   "source": [
    "path = \"./\"\n",
    "print(os.path.getsize(path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28319c41",
   "metadata": {},
   "source": [
    "### os.scandir 获取指定路径下的 子目录 and/or 文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "02cf26d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file name: bi_container.ipynb\n",
      "\t file name: bi_container ; extension: .ipynb\n",
      "file name: bi_data_reading_and_writing.ipynb\n",
      "\t file name: bi_data_reading_and_writing ; extension: .ipynb\n",
      "file name: bi_mutil_thread.ipynb\n",
      "\t file name: bi_mutil_thread ; extension: .ipynb\n",
      "file name: bi_string.ipynb\n",
      "\t file name: bi_string ; extension: .ipynb\n",
      "file name: cpp_container_struct.ipynb\n",
      "\t file name: cpp_container_struct ; extension: .ipynb\n",
      "file name: cpp_eigen.ipynb\n",
      "\t file name: cpp_eigen ; extension: .ipynb\n",
      "file name: cpp_vins.ipynb\n",
      "\t file name: cpp_vins ; extension: .ipynb\n",
      "dir name: data\n",
      "file name: jupyter.ipynb\n",
      "\t file name: jupyter ; extension: .ipynb\n",
      "file name: opencv.ipynb\n",
      "\t file name: opencv ; extension: .ipynb\n",
      "dir name: opencv_data\n",
      "file name: problem_DP.ipynb\n",
      "\t file name: problem_DP ; extension: .ipynb\n",
      "file name: problem_Math.ipynb\n",
      "\t file name: problem_Math ; extension: .ipynb\n",
      "file name: Problem_ShortestPath.ipynb\n",
      "\t file name: Problem_ShortestPath ; extension: .ipynb\n",
      "file name: problem_Stock.ipynb\n",
      "\t file name: problem_Stock ; extension: .ipynb\n",
      "file name: problem_subsequence_and_subarray.ipynb\n",
      "\t file name: problem_subsequence_and_subarray ; extension: .ipynb\n",
      "file name: problem_Tree.ipynb\n",
      "\t file name: problem_Tree ; extension: .ipynb\n",
      "file name: problem_Trie.ipynb\n",
      "\t file name: problem_Trie ; extension: .ipynb\n",
      "file name: python_datetime.ipynb\n",
      "\t file name: python_datetime ; extension: .ipynb\n",
      "file name: python_enumerate.ipynb\n",
      "\t file name: python_enumerate ; extension: .ipynb\n",
      "file name: python_osm.ipynb\n",
      "\t file name: python_osm ; extension: .ipynb\n",
      "file name: python_selenium.ipynb\n",
      "\t file name: python_selenium ; extension: .ipynb\n",
      "dir name: temp\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "path = \"./\"\n",
    "with os.scandir(path) as it: # 仅扫描指定path下的子目录和文件\n",
    "    for entry in it: # entry is <class 'posix.DirEntry'>\n",
    "        if not entry.name.startswith('.'):\n",
    "            # print(type(entry))\n",
    "            if entry.is_dir():\n",
    "                print(\"dir name:\", entry.name)\n",
    "            if entry.is_file():\n",
    "                print(\"file name:\", entry.name)\n",
    "                filename, extension = os.path.splitext(entry.name)\n",
    "                print(\"\\t file name:\", filename, \"; extension:\", extension)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f18c9c",
   "metadata": {},
   "source": [
    "### os.listdir 获取指定路径下的 子目录 and/or 文件 的字符串"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "19610d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bi_container.ipynb\n",
      "bi_data_reading_and_writing.ipynb\n",
      "bi_mutil_thread.ipynb\n",
      "bi_string.ipynb\n",
      "cpp_container_struct.ipynb\n",
      "cpp_eigen.ipynb\n",
      "cpp_vins.ipynb\n",
      "data\n",
      "jupyter.ipynb\n",
      "opencv.ipynb\n",
      "opencv_data\n",
      "problem_DP.ipynb\n",
      "problem_Math.ipynb\n",
      "Problem_ShortestPath.ipynb\n",
      "problem_Stock.ipynb\n",
      "problem_subsequence_and_subarray.ipynb\n",
      "problem_Tree.ipynb\n",
      "problem_Trie.ipynb\n",
      "python_datetime.ipynb\n",
      "python_enumerate.ipynb\n",
      "python_osm.ipynb\n",
      "python_selenium.ipynb\n",
      "temp\n"
     ]
    }
   ],
   "source": [
    "path = \"./\"\n",
    "for item in os.listdir(path): # item is <class 'str'>\n",
    "    if not item.startswith('.'):\n",
    "        # print(type(item))\n",
    "        print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d9631b",
   "metadata": {},
   "source": [
    "### os.mkdir 新建目录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "02dbcf8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dir name: data\n",
      "dir name: opencv_data\n",
      "dir name: temp\n",
      "dir name: temp2\n"
     ]
    }
   ],
   "source": [
    "path = \"./temp2\"\n",
    "if not os.path.exists(path):\n",
    "    os.mkdir(path)\n",
    "else:\n",
    "    print(path,\"已存在\")\n",
    "\n",
    "with os.scandir(\"./\") as it: # 仅扫描指定path下的子目录和文件\n",
    "    for entry in it:\n",
    "        if not entry.name.startswith('.') and entry.is_dir():\n",
    "                print(\"dir name:\", entry.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31999d77",
   "metadata": {},
   "source": [
    "### os.rename 重命名"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "d3c1caa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./temp/data_python3.csv 已存在，无法重命名\n"
     ]
    }
   ],
   "source": [
    "old = \"./temp/data_python2.csv\"\n",
    "new = \"./temp/data_python3.csv\"\n",
    "if os.path.exists(new):\n",
    "    print(new, \"已存在，无法重命名\")\n",
    "else:\n",
    "    if not os.path.exists(old):\n",
    "        print(old, \"不存在\")\n",
    "    else:\n",
    "        os.rename(old,new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670d2b62",
   "metadata": {},
   "source": [
    "### os.replace 重命名"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "0b3ec3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "old = \"./temp/data_python3.csv\"\n",
    "new = \"./temp/data_python2.csv\"\n",
    "if os.path.exists(new):\n",
    "    print(new, \"已存在，无法重命名\")\n",
    "else:\n",
    "    if not os.path.exists(old):\n",
    "        print(old, \"不存在\")\n",
    "    else:\n",
    "        os.replace(old,new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be12c320",
   "metadata": {},
   "source": [
    "### os.remove 删除文件，不能删除目录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "46712009",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./temp/data_python.csv\"\n",
    "\n",
    "if os.path.isfile(path):\n",
    "    os.remove(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711eeee9",
   "metadata": {},
   "source": [
    "### os.rmdir 删除空目录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "c3f8acfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dir name: data\n",
      "dir name: opencv_data\n",
      "dir name: temp\n"
     ]
    }
   ],
   "source": [
    "path = \"./temp2\"\n",
    "if os.path.exists(path) == True:\n",
    "    os.rmdir(path)\n",
    "\n",
    "with os.scandir(\"./\") as it: # 仅扫描指定path下的子目录和文件\n",
    "    for entry in it:\n",
    "        if not entry.name.startswith('.') and entry.is_dir():\n",
    "                print(\"dir name:\", entry.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf740fd",
   "metadata": {},
   "source": [
    "### shutil.rmtree 删除目录树\n",
    "https://docs.python.org/zh-cn/3/library/shutil.html#shutil.rmtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "a8ddf678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dir name: data\n",
      "dir name: opencv_data\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "path = \"./temp\"\n",
    "if os.path.exists(path):\n",
    "    shutil.rmtree(path)\n",
    "\n",
    "with os.scandir(\"./\") as it: # 仅扫描指定path下的子目录和文件\n",
    "    for entry in it:\n",
    "        if not entry.name.startswith('.') and entry.is_dir():\n",
    "                print(\"dir name:\", entry.name)\n",
    "\n",
    "os.mkdir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d853eb",
   "metadata": {},
   "source": [
    "### os.walk 遍历目录树，获取所有目录和文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0e5b93b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "dirpath: ./\n",
      "\n",
      "dirnames: ['.ipynb_checkpoints', 'data', 'opencv_data']\n",
      "\n",
      "filenames: ['bi_container.ipynb', 'bi_data_reading_and_writing.ipynb', 'bi_mutil_thread.ipynb', 'bi_string.ipynb', 'cpp_container_struct.ipynb', 'cpp_eigen.ipynb', 'cpp_vins.ipynb', 'jupyter.ipynb', 'opencv.ipynb', 'problem_DP.ipynb', 'problem_Math.ipynb', 'Problem_ShortestPath.ipynb', 'problem_Stock.ipynb', 'problem_subsequence_and_subarray.ipynb', 'problem_Tree.ipynb', 'problem_Trie.ipynb', 'python_datetime.ipynb', 'python_enumerate.ipynb', 'python_osm.ipynb', 'python_selenium.ipynb']\n",
      "\n",
      "dirpath: ./.ipynb_checkpoints\n",
      "\n",
      "dirnames: []\n",
      "\n",
      "filenames: ['bi_container-checkpoint.ipynb', 'bi_data_reading_and_writing-checkpoint.ipynb', 'bi_mutil_thread-checkpoint.ipynb', 'bi_string-checkpoint.ipynb', 'cpp_container_struct-checkpoint.ipynb', 'cpp_eigen-checkpoint.ipynb', 'cpp_vins-checkpoint.ipynb', 'jupyter-checkpoint.ipynb', 'opencv-checkpoint.ipynb', 'problem_DP-checkpoint.ipynb', 'problem_Math-checkpoint.ipynb', 'Problem_ShortestPath-checkpoint.ipynb', 'problem_Stock-checkpoint.ipynb', 'problem_subsequence_and_subarray-checkpoint.ipynb', 'problem_Tree-checkpoint.ipynb', 'problem_Trie-checkpoint.ipynb', 'python_datetime-checkpoint.ipynb', 'python_enumerate-checkpoint.ipynb', 'python_osm-checkpoint.ipynb', 'python_selenium-checkpoint.ipynb']\n",
      "\n",
      "dirpath: ./data\n",
      "\n",
      "dirnames: []\n",
      "\n",
      "filenames: ['macau.osm', 'test.html']\n",
      "\n",
      "dirpath: ./opencv_data\n",
      "\n",
      "dirnames: ['Chapter 11', 'Chapter 12', 'Chapter 13', 'Chapter 14', 'Chapter 15', 'Chapter 16', 'Chapter 17', 'Chapter 18', 'Chapter 19', 'Chapter 21', 'Chapter 3', 'Chapter 4', 'Chapter 9']\n",
      "\n",
      "filenames: ['cat.jpg', 'cat1.jpg', 'cat_gray.png', 'chaplin.mp4', 'dog.jpg', 'dog_gray.jpg']\n",
      "\n",
      "dirpath: ./opencv_data/Chapter 11\n",
      "\n",
      "dirnames: []\n",
      "\n",
      "filenames: ['harris.py', 'test_1.jpg']\n",
      "\n",
      "dirpath: ./opencv_data/Chapter 12\n",
      "\n",
      "dirnames: []\n",
      "\n",
      "filenames: ['box.png', 'box_in_scene.png', 'Match-1.py', 'Match-k.py', 'sift.py', 'test_1.jpg']\n",
      "\n",
      "dirpath: ./opencv_data/Chapter 13\n",
      "\n",
      "dirnames: ['__pycache__']\n",
      "\n",
      "filenames: ['ImageStiching.py', 'left_01.png', 'right_01.png', 'Stitcher.py']\n",
      "\n",
      "dirpath: ./opencv_data/Chapter 13/__pycache__\n",
      "\n",
      "dirnames: []\n",
      "\n",
      "filenames: ['Stitcher.cpython-35.pyc']\n",
      "\n",
      "dirpath: ./opencv_data/Chapter 14\n",
      "\n",
      "dirnames: ['cnn_data', 'test_images', 'train_data', '__pycache__']\n",
      "\n",
      "filenames: ['Parking.py', 'parking_video.mp4', 'park_test.py', 'spot_dict.pickle', 'train.py', 'with_parking.jpg']\n",
      "\n",
      "dirpath: ./opencv_data/Chapter 14/cnn_data\n",
      "\n",
      "dirnames: []\n",
      "\n",
      "filenames: ['spot1.jpg', 'spot10.jpg', 'spot100.jpg', 'spot101.jpg', 'spot102.jpg', 'spot103.jpg', 'spot104.jpg', 'spot105.jpg', 'spot106.jpg', 'spot107.jpg', 'spot108.jpg', 'spot109.jpg', 'spot11.jpg', 'spot110.jpg', 'spot111.jpg', 'spot112.jpg', 'spot113.jpg', 'spot114.jpg', 'spot115.jpg', 'spot116.jpg', 'spot117.jpg', 'spot118.jpg', 'spot119.jpg', 'spot12.jpg', 'spot120.jpg', 'spot121.jpg', 'spot122.jpg', 'spot123.jpg', 'spot124.jpg', 'spot125.jpg', 'spot126.jpg', 'spot127.jpg', 'spot128.jpg', 'spot129.jpg', 'spot13.jpg', 'spot130.jpg', 'spot131.jpg', 'spot132.jpg', 'spot133.jpg', 'spot134.jpg', 'spot135.jpg', 'spot136.jpg', 'spot137.jpg', 'spot138.jpg', 'spot139.jpg', 'spot14.jpg', 'spot140.jpg', 'spot141.jpg', 'spot142.jpg', 'spot143.jpg', 'spot144.jpg', 'spot145.jpg', 'spot146.jpg', 'spot147.jpg', 'spot148.jpg', 'spot149.jpg', 'spot15.jpg', 'spot150.jpg', 'spot151.jpg', 'spot152.jpg', 'spot153.jpg', 'spot154.jpg', 'spot155.jpg', 'spot156.jpg', 'spot157.jpg', 'spot158.jpg', 'spot159.jpg', 'spot16.jpg', 'spot160.jpg', 'spot161.jpg', 'spot162.jpg', 'spot163.jpg', 'spot164.jpg', 'spot165.jpg', 'spot166.jpg', 'spot167.jpg', 'spot168.jpg', 'spot169.jpg', 'spot17.jpg', 'spot170.jpg', 'spot171.jpg', 'spot172.jpg', 'spot173.jpg', 'spot174.jpg', 'spot175.jpg', 'spot176.jpg', 'spot177.jpg', 'spot178.jpg', 'spot179.jpg', 'spot18.jpg', 'spot180.jpg', 'spot181.jpg', 'spot182.jpg', 'spot183.jpg', 'spot184.jpg', 'spot185.jpg', 'spot186.jpg', 'spot187.jpg', 'spot188.jpg', 'spot189.jpg', 'spot19.jpg', 'spot190.jpg', 'spot191.jpg', 'spot192.jpg', 'spot193.jpg', 'spot194.jpg', 'spot195.jpg', 'spot196.jpg', 'spot197.jpg', 'spot198.jpg', 'spot199.jpg', 'spot2.jpg', 'spot20.jpg', 'spot200.jpg', 'spot201.jpg', 'spot202.jpg', 'spot203.jpg', 'spot204.jpg', 'spot205.jpg', 'spot206.jpg', 'spot207.jpg', 'spot208.jpg', 'spot209.jpg', 'spot21.jpg', 'spot210.jpg', 'spot211.jpg', 'spot212.jpg', 'spot213.jpg', 'spot214.jpg', 'spot215.jpg', 'spot216.jpg', 'spot217.jpg', 'spot218.jpg', 'spot219.jpg', 'spot22.jpg', 'spot220.jpg', 'spot221.jpg', 'spot222.jpg', 'spot223.jpg', 'spot224.jpg', 'spot225.jpg', 'spot226.jpg', 'spot227.jpg', 'spot228.jpg', 'spot229.jpg', 'spot23.jpg', 'spot230.jpg', 'spot231.jpg', 'spot232.jpg', 'spot233.jpg', 'spot234.jpg', 'spot235.jpg', 'spot236.jpg', 'spot237.jpg', 'spot238.jpg', 'spot239.jpg', 'spot24.jpg', 'spot240.jpg', 'spot241.jpg', 'spot242.jpg', 'spot243.jpg', 'spot244.jpg', 'spot245.jpg', 'spot246.jpg', 'spot247.jpg', 'spot248.jpg', 'spot249.jpg', 'spot25.jpg', 'spot250.jpg', 'spot251.jpg', 'spot252.jpg', 'spot253.jpg', 'spot254.jpg', 'spot255.jpg', 'spot256.jpg', 'spot257.jpg', 'spot258.jpg', 'spot259.jpg', 'spot26.jpg', 'spot260.jpg', 'spot261.jpg', 'spot262.jpg', 'spot263.jpg', 'spot264.jpg', 'spot265.jpg', 'spot266.jpg', 'spot267.jpg', 'spot268.jpg', 'spot269.jpg', 'spot27.jpg', 'spot270.jpg', 'spot271.jpg', 'spot272.jpg', 'spot273.jpg', 'spot274.jpg', 'spot275.jpg', 'spot276.jpg', 'spot277.jpg', 'spot278.jpg', 'spot279.jpg', 'spot28.jpg', 'spot280.jpg', 'spot281.jpg', 'spot282.jpg', 'spot283.jpg', 'spot284.jpg', 'spot285.jpg', 'spot286.jpg', 'spot287.jpg', 'spot288.jpg', 'spot289.jpg', 'spot29.jpg', 'spot290.jpg', 'spot291.jpg', 'spot292.jpg', 'spot293.jpg', 'spot294.jpg', 'spot295.jpg', 'spot296.jpg', 'spot297.jpg', 'spot298.jpg', 'spot299.jpg', 'spot3.jpg', 'spot30.jpg', 'spot300.jpg', 'spot301.jpg', 'spot302.jpg', 'spot303.jpg', 'spot304.jpg', 'spot305.jpg', 'spot306.jpg', 'spot307.jpg', 'spot308.jpg', 'spot309.jpg', 'spot31.jpg', 'spot310.jpg', 'spot311.jpg', 'spot312.jpg', 'spot313.jpg', 'spot314.jpg', 'spot315.jpg', 'spot316.jpg', 'spot317.jpg', 'spot318.jpg', 'spot319.jpg', 'spot32.jpg', 'spot320.jpg', 'spot321.jpg', 'spot322.jpg', 'spot323.jpg', 'spot324.jpg', 'spot325.jpg', 'spot326.jpg', 'spot327.jpg', 'spot328.jpg', 'spot329.jpg', 'spot33.jpg', 'spot330.jpg', 'spot331.jpg', 'spot332.jpg', 'spot333.jpg', 'spot334.jpg', 'spot335.jpg', 'spot336.jpg', 'spot337.jpg', 'spot338.jpg', 'spot339.jpg', 'spot34.jpg', 'spot340.jpg', 'spot341.jpg', 'spot342.jpg', 'spot343.jpg', 'spot344.jpg', 'spot345.jpg', 'spot346.jpg', 'spot347.jpg', 'spot348.jpg', 'spot349.jpg', 'spot35.jpg', 'spot350.jpg', 'spot351.jpg', 'spot352.jpg', 'spot353.jpg', 'spot354.jpg', 'spot355.jpg', 'spot356.jpg', 'spot357.jpg', 'spot358.jpg', 'spot359.jpg', 'spot36.jpg', 'spot360.jpg', 'spot361.jpg', 'spot362.jpg', 'spot363.jpg', 'spot364.jpg', 'spot365.jpg', 'spot366.jpg', 'spot367.jpg', 'spot368.jpg', 'spot369.jpg', 'spot37.jpg', 'spot370.jpg', 'spot371.jpg', 'spot372.jpg', 'spot373.jpg', 'spot374.jpg', 'spot375.jpg', 'spot376.jpg', 'spot377.jpg', 'spot378.jpg', 'spot379.jpg', 'spot38.jpg', 'spot380.jpg', 'spot381.jpg', 'spot382.jpg', 'spot383.jpg', 'spot384.jpg', 'spot385.jpg', 'spot386.jpg', 'spot387.jpg', 'spot388.jpg', 'spot389.jpg', 'spot39.jpg', 'spot390.jpg', 'spot391.jpg', 'spot392.jpg', 'spot393.jpg', 'spot394.jpg', 'spot395.jpg', 'spot396.jpg', 'spot397.jpg', 'spot398.jpg', 'spot399.jpg', 'spot4.jpg', 'spot40.jpg', 'spot400.jpg', 'spot401.jpg', 'spot402.jpg', 'spot403.jpg', 'spot404.jpg', 'spot405.jpg', 'spot406.jpg', 'spot407.jpg', 'spot408.jpg', 'spot409.jpg', 'spot41.jpg', 'spot410.jpg', 'spot411.jpg', 'spot412.jpg', 'spot413.jpg', 'spot414.jpg', 'spot415.jpg', 'spot416.jpg', 'spot417.jpg', 'spot418.jpg', 'spot419.jpg', 'spot42.jpg', 'spot420.jpg', 'spot421.jpg', 'spot422.jpg', 'spot423.jpg', 'spot424.jpg', 'spot425.jpg', 'spot426.jpg', 'spot427.jpg', 'spot428.jpg', 'spot429.jpg', 'spot43.jpg', 'spot430.jpg', 'spot431.jpg', 'spot432.jpg', 'spot433.jpg', 'spot434.jpg', 'spot435.jpg', 'spot436.jpg', 'spot437.jpg', 'spot438.jpg', 'spot439.jpg', 'spot44.jpg', 'spot440.jpg', 'spot441.jpg', 'spot442.jpg', 'spot443.jpg', 'spot444.jpg', 'spot445.jpg', 'spot446.jpg', 'spot447.jpg', 'spot448.jpg', 'spot449.jpg', 'spot45.jpg', 'spot450.jpg', 'spot451.jpg', 'spot452.jpg', 'spot453.jpg', 'spot454.jpg', 'spot455.jpg', 'spot456.jpg', 'spot457.jpg', 'spot458.jpg', 'spot459.jpg', 'spot46.jpg', 'spot460.jpg', 'spot461.jpg', 'spot462.jpg', 'spot463.jpg', 'spot464.jpg', 'spot465.jpg', 'spot466.jpg', 'spot467.jpg', 'spot468.jpg', 'spot469.jpg', 'spot47.jpg', 'spot470.jpg', 'spot471.jpg', 'spot472.jpg', 'spot473.jpg', 'spot474.jpg', 'spot475.jpg', 'spot476.jpg', 'spot477.jpg', 'spot478.jpg', 'spot479.jpg', 'spot48.jpg', 'spot480.jpg', 'spot481.jpg', 'spot482.jpg', 'spot483.jpg', 'spot484.jpg', 'spot485.jpg', 'spot486.jpg', 'spot487.jpg', 'spot488.jpg', 'spot489.jpg', 'spot49.jpg', 'spot490.jpg', 'spot491.jpg', 'spot492.jpg', 'spot493.jpg', 'spot494.jpg', 'spot495.jpg', 'spot496.jpg', 'spot497.jpg', 'spot498.jpg', 'spot499.jpg', 'spot5.jpg', 'spot50.jpg', 'spot500.jpg', 'spot501.jpg', 'spot502.jpg', 'spot503.jpg', 'spot504.jpg', 'spot505.jpg', 'spot506.jpg', 'spot507.jpg', 'spot508.jpg', 'spot509.jpg', 'spot51.jpg', 'spot510.jpg', 'spot511.jpg', 'spot512.jpg', 'spot513.jpg', 'spot514.jpg', 'spot515.jpg', 'spot516.jpg', 'spot517.jpg', 'spot518.jpg', 'spot519.jpg', 'spot52.jpg', 'spot520.jpg', 'spot521.jpg', 'spot522.jpg', 'spot523.jpg', 'spot524.jpg', 'spot525.jpg', 'spot526.jpg', 'spot527.jpg', 'spot528.jpg', 'spot529.jpg', 'spot53.jpg', 'spot530.jpg', 'spot531.jpg', 'spot532.jpg', 'spot533.jpg', 'spot534.jpg', 'spot535.jpg', 'spot536.jpg', 'spot537.jpg', 'spot538.jpg', 'spot539.jpg', 'spot54.jpg', 'spot540.jpg', 'spot541.jpg', 'spot542.jpg', 'spot543.jpg', 'spot544.jpg', 'spot545.jpg', 'spot546.jpg', 'spot547.jpg', 'spot548.jpg', 'spot549.jpg', 'spot55.jpg', 'spot550.jpg', 'spot551.jpg', 'spot552.jpg', 'spot553.jpg', 'spot554.jpg', 'spot555.jpg', 'spot56.jpg', 'spot57.jpg', 'spot58.jpg', 'spot59.jpg', 'spot6.jpg', 'spot60.jpg', 'spot61.jpg', 'spot62.jpg', 'spot63.jpg', 'spot64.jpg', 'spot65.jpg', 'spot66.jpg', 'spot67.jpg', 'spot68.jpg', 'spot69.jpg', 'spot7.jpg', 'spot70.jpg', 'spot71.jpg', 'spot72.jpg', 'spot73.jpg', 'spot74.jpg', 'spot75.jpg', 'spot76.jpg', 'spot77.jpg', 'spot78.jpg', 'spot79.jpg', 'spot8.jpg', 'spot80.jpg', 'spot81.jpg', 'spot82.jpg', 'spot83.jpg', 'spot84.jpg', 'spot85.jpg', 'spot86.jpg', 'spot87.jpg', 'spot88.jpg', 'spot89.jpg', 'spot9.jpg', 'spot90.jpg', 'spot91.jpg', 'spot92.jpg', 'spot93.jpg', 'spot94.jpg', 'spot95.jpg', 'spot96.jpg', 'spot97.jpg', 'spot98.jpg', 'spot99.jpg']\n",
      "\n",
      "dirpath: ./opencv_data/Chapter 14/test_images\n",
      "\n",
      "dirnames: []\n",
      "\n",
      "filenames: ['scene1380.jpg', 'scene1410.jpg']\n",
      "\n",
      "dirpath: ./opencv_data/Chapter 14/train_data\n",
      "\n",
      "dirnames: ['test', 'train']\n",
      "\n",
      "filenames: []\n",
      "\n",
      "dirpath: ./opencv_data/Chapter 14/train_data/test\n",
      "\n",
      "dirnames: ['empty', 'occupied']\n",
      "\n",
      "filenames: []\n",
      "\n",
      "dirpath: ./opencv_data/Chapter 14/train_data/test/empty\n",
      "\n",
      "dirnames: []\n",
      "\n",
      "filenames: ['spot1.jpg', 'spot124.jpg', 'spot156.jpg', 'spot162.jpg', 'spot167.jpg', 'spot169.jpg', 'spot170.jpg', 'spot179.jpg', 'spot216.jpg', 'spot224.jpg', 'spot226.jpg', 'spot232.jpg', 'spot299.jpg', 'spot327.jpg', 'spot350.jpg', 'spot372.jpg', 'spot373.jpg', 'spot416.jpg', 'spot420.jpg', 'spot429.jpg', 'spot442.jpg', 'spot459.jpg', 'spot466.jpg', 'spot477.jpg', 'spot485.jpg', 'spot487.jpg', 'spot490.jpg', 'spot491.jpg', 'spot509.jpg', 'spot530.jpg', 'spot538.jpg', 'spot539.jpg', 'spot541.jpg', 'spot65.jpg', 'spot78.jpg', 'spot81.jpg', 'spot85.jpg', 'spot89.jpg']\n",
      "\n",
      "dirpath: ./opencv_data/Chapter 14/train_data/test/occupied\n",
      "\n",
      "dirnames: []\n",
      "\n",
      "filenames: ['spot100.jpg', 'spot115.jpg', 'spot121.jpg', 'spot123.jpg', 'spot129.jpg', 'spot130.jpg', 'spot136.jpg', 'spot138.jpg', 'spot143.jpg', 'spot146.jpg', 'spot147.jpg', 'spot148.jpg', 'spot15.jpg', 'spot151.jpg', 'spot152.jpg', 'spot154.jpg', 'spot163.jpg', 'spot17.jpg', 'spot180.jpg', 'spot181.jpg', 'spot182.jpg', 'spot187.jpg', 'spot189.jpg', 'spot19.jpg', 'spot193.jpg', 'spot205.jpg', 'spot207.jpg', 'spot209.jpg', 'spot210.jpg', 'spot211.jpg', 'spot218.jpg', 'spot235.jpg', 'spot24.jpg', 'spot245.jpg', 'spot249.jpg', 'spot25.jpg', 'spot254.jpg', 'spot257.jpg', 'spot258.jpg', 'spot259.jpg', 'spot26.jpg', 'spot261.jpg', 'spot263.jpg', 'spot267.jpg', 'spot268.jpg', 'spot271.jpg', 'spot273.jpg', 'spot278.jpg', 'spot289.jpg', 'spot291.jpg', 'spot293.jpg', 'spot302.jpg', 'spot303.jpg', 'spot308.jpg', 'spot314.jpg', 'spot317.jpg', 'spot318.jpg', 'spot319.jpg', 'spot324.jpg', 'spot330.jpg', 'spot331.jpg', 'spot334.jpg', 'spot339.jpg', 'spot341.jpg', 'spot342.jpg', 'spot343.jpg', 'spot344.jpg', 'spot346.jpg', 'spot351.jpg', 'spot354.jpg', 'spot356.jpg', 'spot367.jpg', 'spot371.jpg', 'spot383.jpg', 'spot386.jpg', 'spot392.jpg', 'spot393.jpg', 'spot4.jpg', 'spot402.jpg', 'spot403.jpg', 'spot404.jpg', 'spot405.jpg', 'spot410.jpg', 'spot418.jpg', 'spot423.jpg', 'spot425.jpg', 'spot426.jpg', 'spot435.jpg', 'spot437.jpg', 'spot439.jpg', 'spot44.jpg', 'spot446.jpg', 'spot449.jpg', 'spot451.jpg', 'spot454.jpg', 'spot464.jpg', 'spot469.jpg', 'spot470.jpg', 'spot471.jpg', 'spot472.jpg', 'spot476.jpg', 'spot481.jpg', 'spot486.jpg', 'spot49.jpg', 'spot493.jpg', 'spot497.jpg', 'spot5.jpg', 'spot50.jpg', 'spot504.jpg', 'spot513.jpg', 'spot521.jpg', 'spot523.jpg', 'spot532.jpg', 'spot534.jpg', 'spot536.jpg', 'spot54.jpg', 'spot56.jpg', 'spot60.jpg', 'spot63.jpg', 'spot7.jpg', 'spot71.jpg', 'spot8.jpg', 'spot83.jpg', 'spot86.jpg', 'spot96.jpg', 'spot98.jpg']\n",
      "\n",
      "dirpath: ./opencv_data/Chapter 14/train_data/train\n",
      "\n",
      "dirnames: ['empty', 'occupied']\n",
      "\n",
      "filenames: []\n",
      "\n",
      "dirpath: ./opencv_data/Chapter 14/train_data/train/empty\n",
      "\n",
      "dirnames: []\n",
      "\n",
      "filenames: ['spot106.jpg', 'spot122.jpg', 'spot13.jpg', 'spot155.jpg', 'spot159.jpg', 'spot161.jpg', 'spot164.jpg', 'spot165.jpg', 'spot166.jpg', 'spot172.jpg', 'spot173.jpg', 'spot174.jpg', 'spot212.jpg', 'spot214.jpg', 'spot215.jpg', 'spot221.jpg', 'spot223.jpg', 'spot227.jpg', 'spot228.jpg', 'spot229.jpg', 'spot230.jpg', 'spot233.jpg', 'spot234.jpg', 'spot236.jpg', 'spot240.jpg', 'spot272.jpg', 'spot284.jpg', 'spot285.jpg', 'spot286.jpg', 'spot290.jpg', 'spot296.jpg', 'spot298.jpg', 'spot300.jpg', 'spot304.jpg', 'spot305.jpg', 'spot306.jpg', 'spot307.jpg', 'spot32.jpg', 'spot326.jpg', 'spot33.jpg', 'spot345.jpg', 'spot352.jpg', 'spot353.jpg', 'spot357.jpg', 'spot359.jpg', 'spot360.jpg', 'spot361.jpg', 'spot363.jpg', 'spot366.jpg', 'spot369.jpg', 'spot37.jpg', 'spot370.jpg', 'spot374.jpg', 'spot375.jpg', 'spot407.jpg', 'spot41.jpg', 'spot411.jpg', 'spot412.jpg', 'spot413.jpg', 'spot422.jpg', 'spot424.jpg', 'spot431.jpg', 'spot432.jpg', 'spot433.jpg', 'spot438.jpg', 'spot440.jpg', 'spot444.jpg', 'spot458.jpg', 'spot460.jpg', 'spot465.jpg', 'spot468.jpg', 'spot480.jpg', 'spot483.jpg', 'spot488.jpg', 'spot489.jpg', 'spot494.jpg', 'spot496.jpg', 'spot498.jpg', 'spot501.jpg', 'spot502.jpg', 'spot505.jpg', 'spot506.jpg', 'spot507.jpg', 'spot508.jpg', 'spot524.jpg', 'spot526.jpg', 'spot528.jpg', 'spot533.jpg', 'spot537.jpg', 'spot542.jpg', 'spot543.jpg', 'spot544.jpg', 'spot545.jpg', 'spot75.jpg', 'spot84.jpg', 'spot87.jpg']\n",
      "\n",
      "dirpath: ./opencv_data/Chapter 14/train_data/train/occupied\n",
      "\n",
      "dirnames: []\n",
      "\n",
      "filenames: ['spot10.jpg', 'spot101.jpg', 'spot102.jpg', 'spot103.jpg', 'spot104.jpg', 'spot105.jpg', 'spot107.jpg', 'spot108.jpg', 'spot109.jpg', 'spot11.jpg', 'spot110.jpg', 'spot111.jpg', 'spot112.jpg', 'spot113.jpg', 'spot114.jpg', 'spot116.jpg', 'spot117.jpg', 'spot118.jpg', 'spot119.jpg', 'spot12.jpg', 'spot120.jpg', 'spot125.jpg', 'spot126.jpg', 'spot127.jpg', 'spot128.jpg', 'spot131.jpg', 'spot132.jpg', 'spot133.jpg', 'spot134.jpg', 'spot135.jpg', 'spot137.jpg', 'spot139.jpg', 'spot14.jpg', 'spot140.jpg', 'spot141.jpg', 'spot142.jpg', 'spot144.jpg', 'spot145.jpg', 'spot149.jpg', 'spot150.jpg', 'spot153.jpg', 'spot157.jpg', 'spot158.jpg', 'spot16.jpg', 'spot160.jpg', 'spot168.jpg', 'spot171.jpg', 'spot175.jpg', 'spot176.jpg', 'spot177.jpg', 'spot178.jpg', 'spot18.jpg', 'spot183.jpg', 'spot184.jpg', 'spot185.jpg', 'spot186.jpg', 'spot188.jpg', 'spot190.jpg', 'spot191.jpg', 'spot192.jpg', 'spot194.jpg', 'spot195.jpg', 'spot196.jpg', 'spot197.jpg', 'spot198.jpg', 'spot199.jpg', 'spot2.jpg', 'spot20.jpg', 'spot200.jpg', 'spot201.jpg', 'spot202.jpg', 'spot203.jpg', 'spot204.jpg', 'spot206.jpg', 'spot208.jpg', 'spot21.jpg', 'spot213.jpg', 'spot217.jpg', 'spot219.jpg', 'spot22.jpg', 'spot220.jpg', 'spot222.jpg', 'spot225.jpg', 'spot23.jpg', 'spot231.jpg', 'spot237.jpg', 'spot238.jpg', 'spot239.jpg', 'spot241.jpg', 'spot242.jpg', 'spot243.jpg', 'spot244.jpg', 'spot246.jpg', 'spot247.jpg', 'spot248.jpg', 'spot250.jpg', 'spot251.jpg', 'spot252.jpg', 'spot253.jpg', 'spot255.jpg', 'spot256.jpg', 'spot260.jpg', 'spot262.jpg', 'spot264.jpg', 'spot265.jpg', 'spot266.jpg', 'spot269.jpg', 'spot27.jpg', 'spot270.jpg', 'spot274.jpg', 'spot275.jpg', 'spot276.jpg', 'spot277.jpg', 'spot279.jpg', 'spot28.jpg', 'spot280.jpg', 'spot281.jpg', 'spot282.jpg', 'spot283.jpg', 'spot287.jpg', 'spot288.jpg', 'spot29.jpg', 'spot292.jpg', 'spot294.jpg', 'spot295.jpg', 'spot297.jpg', 'spot3.jpg', 'spot30.jpg', 'spot301.jpg', 'spot309.jpg', 'spot31.jpg', 'spot310.jpg', 'spot311.jpg', 'spot312.jpg', 'spot313.jpg', 'spot315.jpg', 'spot316.jpg', 'spot320.jpg', 'spot321.jpg', 'spot322.jpg', 'spot323.jpg', 'spot325.jpg', 'spot328.jpg', 'spot329.jpg', 'spot332.jpg', 'spot333.jpg', 'spot335.jpg', 'spot336.jpg', 'spot337.jpg', 'spot338.jpg', 'spot34.jpg', 'spot340.jpg', 'spot347.jpg', 'spot348.jpg', 'spot349.jpg', 'spot35.jpg', 'spot355.jpg', 'spot358.jpg', 'spot36.jpg', 'spot362.jpg', 'spot364.jpg', 'spot365.jpg', 'spot368.jpg', 'spot376.jpg', 'spot377.jpg', 'spot378.jpg', 'spot379.jpg', 'spot38.jpg', 'spot380.jpg', 'spot381.jpg', 'spot382.jpg', 'spot384.jpg', 'spot385.jpg', 'spot387.jpg', 'spot388.jpg', 'spot389.jpg', 'spot39.jpg', 'spot390.jpg', 'spot391.jpg', 'spot394.jpg', 'spot395.jpg', 'spot396.jpg', 'spot397.jpg', 'spot398.jpg', 'spot399.jpg', 'spot40.jpg', 'spot400.jpg', 'spot401.jpg', 'spot406.jpg', 'spot408.jpg', 'spot409.jpg', 'spot414.jpg', 'spot415.jpg', 'spot417.jpg', 'spot419.jpg', 'spot42.jpg', 'spot421.jpg', 'spot427.jpg', 'spot428.jpg', 'spot43.jpg', 'spot430.jpg', 'spot434.jpg', 'spot436.jpg', 'spot441.jpg', 'spot443.jpg', 'spot445.jpg', 'spot447.jpg', 'spot448.jpg', 'spot45.jpg', 'spot450.jpg', 'spot452.jpg', 'spot453.jpg', 'spot455.jpg', 'spot456.jpg', 'spot457.jpg', 'spot46.jpg', 'spot461.jpg', 'spot462.jpg', 'spot463.jpg', 'spot467.jpg', 'spot47.jpg', 'spot473.jpg', 'spot474.jpg', 'spot475.jpg', 'spot478.jpg', 'spot479.jpg', 'spot48.jpg', 'spot482.jpg', 'spot484.jpg', 'spot492.jpg', 'spot495.jpg', 'spot499.jpg', 'spot500.jpg', 'spot503.jpg', 'spot51.jpg', 'spot510.jpg', 'spot511.jpg', 'spot512.jpg', 'spot514.jpg', 'spot515.jpg', 'spot516.jpg', 'spot517.jpg', 'spot518.jpg', 'spot519.jpg', 'spot52.jpg', 'spot520.jpg', 'spot522.jpg', 'spot525.jpg', 'spot527.jpg', 'spot529.jpg', 'spot53.jpg', 'spot531.jpg', 'spot535.jpg', 'spot540.jpg', 'spot55.jpg', 'spot57.jpg', 'spot58.jpg', 'spot59.jpg', 'spot6.jpg', 'spot61.jpg', 'spot62.jpg', 'spot64.jpg', 'spot66.jpg', 'spot67.jpg', 'spot68.jpg', 'spot69.jpg', 'spot70.jpg', 'spot72.jpg', 'spot73.jpg', 'spot74.jpg', 'spot76.jpg', 'spot77.jpg', 'spot79.jpg', 'spot80.jpg', 'spot82.jpg', 'spot88.jpg', 'spot9.jpg', 'spot90.jpg', 'spot91.jpg', 'spot92.jpg', 'spot93.jpg', 'spot94.jpg', 'spot95.jpg', 'spot97.jpg', 'spot99.jpg']\n",
      "\n",
      "dirpath: ./opencv_data/Chapter 14/__pycache__\n",
      "\n",
      "dirnames: []\n",
      "\n",
      "filenames: ['Parking.cpython-35.pyc']\n",
      "\n",
      "dirpath: ./opencv_data/Chapter 15\n",
      "\n",
      "dirnames: ['images']\n",
      "\n",
      "filenames: ['get_answer.py']\n",
      "\n",
      "dirpath: ./opencv_data/Chapter 15/images\n",
      "\n",
      "dirnames: []\n",
      "\n",
      "filenames: ['example_test.png', 'test_01.png', 'test_02.png', 'test_03.png', 'test_04.png', 'test_05.png']\n",
      "\n",
      "dirpath: ./opencv_data/Chapter 16\n",
      "\n",
      "dirnames: []\n",
      "\n",
      "filenames: ['back model.py', 'test.avi']\n",
      "\n",
      "dirpath: ./opencv_data/Chapter 17\n",
      "\n",
      "dirnames: []\n",
      "\n",
      "filenames: ['optical flow estimation.py', 'test.avi']\n",
      "\n",
      "dirpath: ./opencv_data/Chapter 18\n",
      "\n",
      "dirnames: ['images', '__pycache__']\n",
      "\n",
      "filenames: ['blob_from_images.py', 'bvlc_googlenet.caffemodel', 'bvlc_googlenet.prototxt', 'synset_words.txt', 'utils_paths.py']\n",
      "\n",
      "dirpath: ./opencv_data/Chapter 18/images\n",
      "\n",
      "dirnames: []\n",
      "\n",
      "filenames: ['beer.png', 'brown_bear.png', 'keyboard.png', 'monitor.png', 'snippet.py', 'space_shuttle.png']\n",
      "\n",
      "dirpath: ./opencv_data/Chapter 18/__pycache__\n",
      "\n",
      "dirnames: []\n",
      "\n",
      "filenames: ['utils_paths.cpython-35.pyc']\n",
      "\n",
      "dirpath: ./opencv_data/Chapter 19\n",
      "\n",
      "dirnames: ['multi-object-tracking', 'multiobject-tracking-dlib']\n",
      "\n",
      "filenames: []\n",
      "\n",
      "dirpath: ./opencv_data/Chapter 19/multi-object-tracking\n",
      "\n",
      "dirnames: ['videos']\n",
      "\n",
      "filenames: ['multi_object_tracking.py']\n",
      "\n",
      "dirpath: ./opencv_data/Chapter 19/multi-object-tracking/videos\n",
      "\n",
      "dirnames: []\n",
      "\n",
      "filenames: ['los_angeles.mp4', 'nascar.mp4', 'soccer_01.mp4', 'soccer_02.mp4']\n",
      "\n",
      "dirpath: ./opencv_data/Chapter 19/multiobject-tracking-dlib\n",
      "\n",
      "dirnames: ['mobilenet_ssd']\n",
      "\n",
      "filenames: ['dlib-19.7.0-cp36-cp36m-win_amd64.whl', 'multi_object_tracking_fast.py', 'multi_object_tracking_slow.py', 'race.mp4', 'race_output_fast.avi', 'race_output_slow.avi', 'utils.py']\n",
      "\n",
      "dirpath: ./opencv_data/Chapter 19/multiobject-tracking-dlib/mobilenet_ssd\n",
      "\n",
      "dirnames: []\n",
      "\n",
      "filenames: ['MobileNetSSD_deploy.caffemodel', 'MobileNetSSD_deploy.prototxt']\n",
      "\n",
      "dirpath: ./opencv_data/Chapter 21\n",
      "\n",
      "dirnames: ['blink-detection', 'Face']\n",
      "\n",
      "filenames: []\n",
      "\n",
      "dirpath: ./opencv_data/Chapter 21/blink-detection\n",
      "\n",
      "dirnames: []\n",
      "\n",
      "filenames: ['detect_blinks.py', 'shape_predictor_68_face_landmarks.dat', 'test.mp4']\n",
      "\n",
      "dirpath: ./opencv_data/Chapter 21/Face\n",
      "\n",
      "dirnames: ['images']\n",
      "\n",
      "filenames: ['detect_face_parts.py', 'shape_predictor_68_face_landmarks.dat']\n",
      "\n",
      "dirpath: ./opencv_data/Chapter 21/Face/images\n",
      "\n",
      "dirnames: []\n",
      "\n",
      "filenames: ['liudehua.jpg', 'liudehua2.jpg']\n",
      "\n",
      "dirpath: ./opencv_data/Chapter 3\n",
      "\n",
      "dirnames: []\n",
      "\n",
      "filenames: ['cat.jpg', 'Image threshold.py']\n",
      "\n",
      "dirpath: ./opencv_data/Chapter 4\n",
      "\n",
      "dirnames: []\n",
      "\n",
      "filenames: ['black hat.py', 'Close computer.py', 'Corrosion operation.py', 'dige.png', 'Expansion operation.py', 'gradient.py', 'Open computer.py', 'pie.png', 'top hat.py', '__init__.py']\n",
      "\n",
      "dirpath: ./opencv_data/Chapter 9\n",
      "\n",
      "dirnames: ['images', '__pycache__']\n",
      "\n",
      "filenames: ['myutils.py', 'ocr_a_reference.png', 'ocr_template_match.py']\n",
      "\n",
      "dirpath: ./opencv_data/Chapter 9/images\n",
      "\n",
      "dirnames: []\n",
      "\n",
      "filenames: ['credit_card_01.png', 'credit_card_02.png', 'credit_card_03.png', 'credit_card_04.png', 'credit_card_05.png', 'ocr_a_reference.png']\n",
      "\n",
      "dirpath: ./opencv_data/Chapter 9/__pycache__\n",
      "\n",
      "dirnames: []\n",
      "\n",
      "filenames: ['myutils.cpython-35.pyc']\n"
     ]
    }
   ],
   "source": [
    "path = \"./\"\n",
    "for dirpath, dirnames, filenames in os.walk(path):  # 遍历目录树\n",
    "    print(\"\\ndirpath:\", dirpath)  # 目录路径的字符串  \n",
    "    print(\"\\ndirnames:\", dirnames)  # dirpath 中子目录名称组成的列表\n",
    "    print(\"\\nfilenames:\", filenames) # dirpath 中非目录文件名称组成的列表"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d6928b",
   "metadata": {},
   "source": [
    "## numpy读写"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262f7fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.save(\"res_brent_3.npy\",container)#保存一个数组\n",
    "numpy.savetxt('res_brent_3.csv', container, delimiter = ',')#保存为CSV格式"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "306.875px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
